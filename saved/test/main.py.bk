import os
import json
import base64
import asyncio
import argparse
from fastapi import FastAPI, WebSocket, BackgroundTasks
from fastapi.responses import JSONResponse
from fastapi.websockets import WebSocketDisconnect
from twilio.rest import Client
import websockets
from dotenv import load_dotenv
import uvicorn
import re
import wave
import os
from datetime import datetime
import numpy as np

load_dotenv(override=True)

# Configuration
TWILIO_ACCOUNT_SID = os.getenv('TWILIO_ACCOUNT_SID')
TWILIO_AUTH_TOKEN = os.getenv('TWILIO_AUTH_TOKEN')
PHONE_NUMBER_FROM = os.getenv('PHONE_NUMBER_FROM')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
raw_domain = os.getenv('GROK_DOMAIN', None)

if raw_domain is None:
    print("Error: GROK_DOMAIN is not set.")
    exit(1)

DOMAIN = re.sub(r'(^\w+:|^)\/\/|\/+$', '', raw_domain) # Strip protocols and trailing slashes from DOMAIN
VOICE = os.getenv('OPENAI_AUDIO_VOICE', 'coral')
OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-mini-realtime-preview-2024-12-17')

PORT = int(os.getenv('PORT', 6060))


print(f"TWILIO_ACCOUNT_SID: {TWILIO_ACCOUNT_SID}")
print(f"TWILIO_AUTH_TOKEN: {TWILIO_AUTH_TOKEN}")
print(f"PHONE_NUMBER_FROM: {PHONE_NUMBER_FROM}")
print(f"OPENAI_API_KEY: {OPENAI_API_KEY}")
print(f"DOMAIN: {DOMAIN}")
print(f"VOICE: {VOICE}")
print(f"OPENAI_MODEL: {OPENAI_MODEL}")
print(f"PORT: {PORT}")

input("Press Enter to continue...")

SYSTEM_MESSAGE = (
    """# Prompt de Sistema - Asistente MyCityHome

Eres el asistente virtual de MyCityHome, una empresa especializada en alquiler de pisos. Tu objetivo es ayudar a los clientes a encontrar la propiedad ideal de manera eficiente.

## Comportamiento Principal
- Proporciona respuestas breves y directas
- Mantén un tono profesional pero amigable
- Prioriza la claridad y precisión en la información

## Funciones Clave
1. Consulta de Propiedades
   - Solicita requisitos específicos: presupuesto, zona, tamaño
   - Confirma detalles importantes antes de hacer recomendaciones
   - Presenta opciones de forma concisa

2. Gestión de Consultas
   - Responde preguntas sobre el proceso de alquiler
   - Informa sobre documentación necesaria
   - Deriva a un agente humano cuando sea necesario

## Formato de Respuestas
- Limita las respuestas a 2-3 oraciones cuando sea posible
- Usa datos concretos: precio, metros cuadrados, ubicación
- Incluye siempre próximos pasos o llamadas a la acción

## Restricciones
- No negociar precios
- No hacer promesas sobre disponibilidad
- No compartir información personal de propietarios
- No gestionar pagos o contratos directamente

## Ejemplo de Interacción
Usuario: "Busco piso en el centro"
Asistente: "¿Cuál es su presupuesto máximo y cuántas habitaciones necesita? Con esta información podré mostrarle las mejores opciones disponibles en el centro."""
)
NOISE_THRESHOLD = float(os.getenv('NOISE_THRESHOLD', '0.7'))  # Default to 600 if not set

LOG_EVENT_TYPES = [
    'error', 'response.content.done', 'rate_limits.updated', 'response.done',
    'input_audio_buffer.committed', 'input_audio_buffer.speech_stopped',
    'input_audio_buffer.speech_started', 'session.created'
]

app = FastAPI()

if not (TWILIO_ACCOUNT_SID and TWILIO_AUTH_TOKEN and PHONE_NUMBER_FROM and OPENAI_API_KEY):
    raise ValueError('Missing Twilio and/or OpenAI environment variables. Please set them in the .env file.')

# Initialize Twilio client
client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)

@app.get('/', response_class=JSONResponse)
async def index_page():
    return {"message": "Twilio Media Stream Server is running!"}

@app.websocket('/media-stream')
async def handle_media_stream(websocket: WebSocket):
    """Handle WebSocket connections between Twilio and OpenAI."""
    print("Client connected")
    await websocket.accept()

    uri =f"wss://api.openai.com/v1/realtime?model={OPENAI_MODEL}"
    additionals_headers={
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "OpenAI-Beta": "realtime=v1"
        }
    
    async with websockets.connect(
        uri=uri,additional_headers=additionals_headers
    ) as openai_ws:
        await initialize_session(openai_ws)
        stream_sid = None
        audio_buffer = []
        wav_file = None
        
        async def receive_from_twilio():
            """Receive audio data from Twilio and send it to the OpenAI Realtime API."""
            nonlocal stream_sid
            nonlocal wav_file
            
            try:
                async for message in websocket.iter_text():
                    data = json.loads(message)
                    if data['event'] == 'media':
                        audio_append = {
                            "type": "input_audio_buffer.append",
                            "audio": data['media']['payload']
                        }

                        # print("Received audio data:", data)
                        # print(audio_append['audio'])
                        # print()
                        
                        # Save audio data
                        audio_data = base64.b64decode(data['media']['payload'])
                        
                        # Initialize WAV file if not already done
                        if wav_file is None:
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            os.makedirs('recordings', exist_ok=True)
                            wav_filename = f'recordings/audio_{timestamp}.wav'
                            wav_file = wave.open(wav_filename, 'wb')
                            wav_file.setnchannels(1)  # Mono audio
                            wav_file.setsampwidth(2)  # 16-bit audio
                            wav_file.setframerate(44100)  # 44.1kHz for better quality
                            print(f"Created new WAV file: {wav_filename}")

                        # Process audio data
                        try:
                            # Convert audio data to numpy array
                            audio_np = np.frombuffer(audio_data, dtype=np.int16).copy()  # Make a writable copy

                            # Basic noise reduction first
                            noise_threshold = NOISE_THRESHOLD * 32767  # Convert from [0,1] range to int16 range
                            audio_np[np.abs(audio_np) < noise_threshold] = 0

                            # print("Audio statistics before filtering:")
                            # print(f"Min value: {np.min(audio_np)}")
                            # print(f"Max value: {np.max(audio_np)}")
                            # print(f"Mean value: {np.mean(np.abs(audio_np))}")
                            # print(f"Number of samples: {len(audio_np)}")
                            # print(f"Number of non-zero samples: {np.count_nonzero(audio_np)}")
                            # print(f"Percentage of signal retained: {(np.count_nonzero(audio_np)/len(audio_np))*100:.2f}%")
                            # print(audio_np)
                            
                            # Then normalize
                            max_val = np.max(np.abs(audio_np))
                            if max_val > 0:
                                audio_np = np.int16(audio_np / max_val * 32767)

                                # Debug information
                                # print("Audio statistics after filtering:")
                                # print(f"Min value: {np.min(audio_np)}")
                                # print(f"Max value: {np.max(audio_np)}")
                                # print(f"Mean value: {np.mean(np.abs(audio_np))}")
                                # print(f"Number of samples: {len(audio_np)}")
                                # print(f"Number of non-zero samples: {np.count_nonzero(audio_np)}")
                                # print(f"Percentage of signal retained: {(np.count_nonzero(audio_np)/len(audio_np))*100:.2f}%")
                                # print(audio_np)

                            # Convert back to bytes
                            audio_data = audio_np.tobytes()

                            # # Write processed audio to file
                            wav_file.writeframes(audio_data)
                            audio_buffer.append(audio_data)
                        except Exception as e:
                            print(f"Error processing audio: {str(e)}")

                        await openai_ws.send(json.dumps(audio_append))
                    elif data['event'] == 'start':
                        stream_sid = data['start']['streamSid']
                        print(f"Incoming stream has started {stream_sid}")
            except WebSocketDisconnect:
                print("Client disconnected.")
                if openai_ws.open:
                    await openai_ws.close()

        async def send_to_twilio():
            """Receive events from the OpenAI Realtime API, send audio back to Twilio."""
            nonlocal stream_sid
            try:
                async for openai_message in openai_ws:
                    response = json.loads(openai_message)
                    if response['type'] in LOG_EVENT_TYPES:
                        print(f"Received event: {response['type']}", response)
                    if response['type'] == 'session.updated':
                        print("Session updated successfully:", response)
                    if response['type'] == 'response.audio.delta' and response.get('delta'):
                        try:
                            audio_payload = base64.b64encode(base64.b64decode(response['delta'])).decode('utf-8')
                            audio_delta = {
                                "event": "media",
                                "streamSid": stream_sid,
                                "media": {
                                    "payload": audio_payload
                                }
                            }
                            await websocket.send_json(audio_delta)
                        except Exception as e:
                            print(f"Error processing audio data: {e}")
            except Exception as e:
                print(f"Error in send_to_twilio: {e}")
        await asyncio.gather(receive_from_twilio(), send_to_twilio())






async def send_initial_conversation_item(openai_ws):
    """Send initial conversation so AI talks first."""
    initial_conversation_item = {
        "type": "conversation.item.create",
        "item": {
            "type": "message",
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": (
                        """# Instrucciones de Presentación

Al iniciar cada interacción con un cliente, deberás:

1. Presentación Personal
   - Identifícate como el asistente virtual de MyCityHome
   - Usa un tono profesional pero cercano
   - No uses nombres propios ni te presentes con un nombre específico

2. Explicación de Rol
   - Menciona que trabajas para MyCityHome
   - Especifica que tu función es ayudar a encontrar propiedades en alquiler
   - Enfatiza que estás ahí para entender sus necesidades específicas

3. Objetivo de la Conversación
   - Indica que tu objetivo es ayudarles a encontrar la propiedad ideal
   - Menciona que harás algunas preguntas para entender mejor sus necesidades
   - Finaliza con una pregunta sobre el tipo de propiedad que buscan

4. Estructura del Saludo
   "Bienvenido/a a MyCityHome. Soy su asistente virtual especializado en ayudarle a encontrar la propiedad ideal para alquilar. Mi objetivo es entender sus necesidades para mostrarle las mejores opciones disponibles. ¿Qué tipo de propiedad está buscando?"

5. Reglas Importantes
   - Mantén la presentación breve y directa
   - No hagas promesas sobre resultados específicos
   - Evita lenguaje técnico o complicado
   - Siempre termina con una pregunta que invite al diálogo.
   
Recuerda que siempre debes ser los más breve posible, para mantener al cliente en contacto y evitar sobrecarga.

Ejemplo de Saludo:
"¡Hola! Soy su asistente virtual de MyCityHome. Mi objetivo es ayudarle a encontrar la propiedad ideal para alquilar. ¿Qué tipo de propiedad está buscando?"""
                    )
                }
            ]
        }
    }
    await openai_ws.send(json.dumps(initial_conversation_item))
    await openai_ws.send(json.dumps({"type": "response.create"}))

async def initialize_session(openai_ws):
    """Control initial session with OpenAI."""
    session_update = {
        "type": "session.update",
        "session": {
            "turn_detection": {"type": "server_vad"},
            "input_audio_format": "g711_ulaw",
            "output_audio_format": "g711_ulaw",
            "voice": VOICE,
            "instructions": SYSTEM_MESSAGE,
            "modalities": ["text", "audio"],
            "temperature": 0.8,
        }
    }
    print('Sending session update:', json.dumps(session_update))
    await openai_ws.send(json.dumps(session_update))

    # Have the AI speak first
    await send_initial_conversation_item(openai_ws)



async def check_number_allowed(to):
    """Check if a number is allowed to be called."""
    try:
        # Uncomment these lines to test numbers. Only add numbers you have permission to call
        OVERRIDE_NUMBERS = ['+34616642830'] 
        if to in OVERRIDE_NUMBERS:             
          return True

        incoming_numbers = client.incoming_phone_numbers.list(phone_number=to)
        if incoming_numbers:
            return True

        outgoing_caller_ids = client.outgoing_caller_ids.list(phone_number=to)
        if outgoing_caller_ids:
            return True

        return False
    except Exception as e:
        print(f"Error checking phone number: {e}")
        return False




async def make_call(phone_number_to_call: str):
    """Make an outbound call."""
    if not phone_number_to_call:
        raise ValueError("Please provide a phone number to call.")

    is_allowed = await check_number_allowed(phone_number_to_call)
    if not is_allowed:
        raise ValueError(f"The number {phone_number_to_call} is not recognized as a valid outgoing number or caller ID.")

    # Ensure compliance with applicable laws and regulations
    # All of the rules of TCPA apply even if a call is made by AI.
    # Do your own diligence for compliance.

    outbound_twiml = (
        f'<?xml version="1.0" encoding="UTF-8"?>'
        f'<Response><Connect><Stream url="wss://{DOMAIN}/media-stream" /></Connect></Response>'
    )

    call = client.calls.create(
        from_=PHONE_NUMBER_FROM,
        to=phone_number_to_call,
        twiml=outbound_twiml
    )

    await log_call_sid(call.sid)

async def log_call_sid(call_sid):
    """Log the call SID."""
    print(f"Call started with SID: {call_sid}")



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run the Twilio AI voice assistant server.")
    parser.add_argument('--call', required=True, help="The phone number to call, e.g., '--call=+18005551212'")
    args = parser.parse_args()

    phone_number = args.call
    print(
        'Our recommendation is to always disclose the use of AI for outbound or inbound calls.\n'
        'Reminder: All of the rules of TCPA apply even if a call is made by AI.\n'
        'Check with your counsel for legal and compliance advice.'
    )

    loop = asyncio.get_event_loop()
    loop.run_until_complete(make_call(phone_number))
    
    uvicorn.run(app, host="0.0.0.0", port=PORT)


    #python main.py --call=+34623551372
    #ngrok http 6060